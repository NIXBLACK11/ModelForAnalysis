{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObt0n3fC3zz0b3zlcD/zPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIXBLACK11/ModelForAnalysis/blob/main/VideoRating2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm_vIQWV6jcY",
        "outputId": "0de4e7b7-3bfc-4d21-9c49-4b891b615f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf screenshot audio"
      ],
      "metadata": {
        "id": "Y2FkU9e29iyA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "audioIndex = 0\n",
        "imageIndex = 0\n",
        "totalTime = 0\n",
        "\n",
        "def extract_screenshots_and_audio(input_video_path, output_screenshots_folder, output_audio_folder):\n",
        "    global audioIndex, imageIndex, totalTime\n",
        "\n",
        "    # Create output folders if they don't exist\n",
        "    os.makedirs(output_screenshots_folder, exist_ok=True)\n",
        "    os.makedirs(output_audio_folder, exist_ok=True)\n",
        "\n",
        "    # Load video\n",
        "    video_clip = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Extract screenshots and calculate mean time duration\n",
        "    screenshots = []\n",
        "    mean_time_duration = 0\n",
        "    for timestamp in range(0, int(video_clip.duration), 5):\n",
        "        screenshot = video_clip.get_frame(timestamp)\n",
        "\n",
        "        # Convert NumPy array to PIL Image\n",
        "        pil_image = Image.fromarray(screenshot)\n",
        "\n",
        "        screenshots.append(pil_image)\n",
        "        mean_time_duration += timestamp\n",
        "\n",
        "        screenshot_path = os.path.join(output_screenshots_folder, f\"screenshot_{imageIndex}.png\")\n",
        "        imageIndex += 1\n",
        "        pil_image.save(screenshot_path)\n",
        "\n",
        "    totalTime += video_clip.duration\n",
        "\n",
        "    # Extract audio\n",
        "    audio = video_clip.audio\n",
        "    audio_path = os.path.join(output_audio_folder, f\"audio_{audioIndex}.wav\")\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "    audioIndex += 1  # Increment audio index for unique filenames\n",
        "\n",
        "    # Close video clip\n",
        "    video_clip.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "\n",
        "  for genre in genres:\n",
        "      input_video_path = \"/content/drive/MyDrive/VideoDataset/\"+genre\n",
        "      output_screenshots_folder = \"/content/screenshot/\"+genre\n",
        "      output_audio_folder = \"/content/audio/\"+genre\n",
        "\n",
        "      totalFiles = 0\n",
        "\n",
        "      for filename in os.listdir(input_video_path):\n",
        "        # Construct the full file path\n",
        "        input_video_file = os.path.join(input_video_path, filename)\n",
        "\n",
        "        # Check if it's a file (not a subdirectory)\n",
        "        if os.path.isfile(input_video_file):\n",
        "            # Call the function with the file path\n",
        "            extract_screenshots_and_audio(input_video_file, output_screenshots_folder, output_audio_folder)\n",
        "            totalFiles += 1\n",
        "\n",
        "      averageTime = totalTime / totalFiles\n",
        "      print(averageTime)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "MXgQPUAY7Nlg",
        "outputId": "c225b92b-7f23-4ce1-f834-7d11ff2f02b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d0017fdb5d3c>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Call the function with the file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mextract_screenshots_and_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_screenshots_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_audio_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mtotalFiles\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d0017fdb5d3c>\u001b[0m in \u001b[0;36mextract_screenshots_and_audio\u001b[0;34m(input_video_path, output_screenshots_folder, output_audio_folder)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmean_time_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_clip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscreenshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_clip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Convert NumPy array to PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-128>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Make a reader for the audio, if any.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mread_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnbytes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the paths\n",
        "base_dir = '/content/screenshot'\n",
        "\n",
        "# Create a dictionary to map genres to their respective folders\n",
        "genre_folders = {\n",
        "    'MrBeastType': 'A',\n",
        "    'VlogType': 'B',\n",
        "    'TechReviewType': 'C',  # Change 'C' to the actual folder name for TechReviewType\n",
        "    'GamingType': 'D',  # Change 'D' to the actual folder name for GamingType\n",
        "    'MinimalistType': 'E'  # Change 'E' to the actual folder name for MinimalistType\n",
        "}\n",
        "\n",
        "# Get the list of image files for each genre\n",
        "genre_images = {}\n",
        "for genre, folder in genre_folders.items():\n",
        "    genre_dir = os.path.join(base_dir, folder)\n",
        "    genre_images[genre] = [os.path.join(genre_dir, img) for img in os.listdir(genre_dir)]\n",
        "\n",
        "# Choose an equal number of images from all classes\n",
        "num_images_per_genre = min(len(images) for images in genre_images.values())\n",
        "for genre in genre_images:\n",
        "    genre_images[genre] = genre_images[genre][:num_images_per_genre]\n",
        "\n",
        "# Split the data into train and test sets for each genre\n",
        "train_images, test_images = {}, {}\n",
        "for genre, images in genre_images.items():\n",
        "    train_images[genre], test_images[genre] = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and test directories for each genre\n",
        "train_dir = '/content/dataset/train/'\n",
        "test_dir = '/content/dataset/test/'\n",
        "\n",
        "for genre in genres:\n",
        "    os.makedirs(os.path.join(train_dir, genre), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, genre), exist_ok=True)\n",
        "\n",
        "# Copy an equal number of images to train and test directories for each genre\n",
        "for genre in genres:\n",
        "    for img in train_images[genre]:\n",
        "        os.system(f'cp \"{img}\" \"{os.path.join(train_dir, genre)}\"')\n",
        "\n",
        "    for img in test_images[genre]:\n",
        "        os.system(f'cp \"{img}\" \"{os.path.join(test_dir, genre)}\"')\n",
        "\n",
        "# Set up image data generators for train and test sets\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Use 'categorical' for multiple classes\n",
        "    classes=genres\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Use 'categorical' for multiple classes\n",
        "    classes=genres\n",
        ")\n"
      ],
      "metadata": {
        "id": "i-ROrny_9qGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Function to create, compile, train, and save model with 'adamax' optimizer\n",
        "def train_and_save_model(train_generator, test_generator):\n",
        "    # Load the VGG16 model and remove the final layer\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(len(genres), activation='softmax')(x)  # Use 'softmax' for multiple classes\n",
        "\n",
        "    # Create a new model by combining the VGG16 base model and the new layers\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(genres), activation='softmax'))  # Use 'softmax' for multiple classes\n",
        "\n",
        "    # Freeze the VGG16 base layers and train the new layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])  # Use 'categorical_crossentropy' for multiple classes\n",
        "\n",
        "    print(\"\\nTraining model with optimizer: adamax\")\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=20,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=test_generator.samples // batch_size\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save('/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_adamax.h5')\n",
        "\n",
        "    # Save the training history to a file\n",
        "    history_path = '/content/drive/MyDrive/VideoDataset/training_history_adamax.pkl'\n",
        "    with open(history_path, 'wb') as file:\n",
        "        pickle.dump(history.history, file)\n",
        "\n",
        "    return history\n",
        "\n",
        "# Set up image data generators for train and test sets\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Use 'categorical' for multiple classes\n",
        "    classes=genres\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Use 'categorical' for multiple classes\n",
        "    classes=genres\n",
        ")\n",
        "\n",
        "# Train and save model with 'adamax' optimizer\n",
        "history = train_and_save_model(train_generator, test_generator)\n",
        "\n",
        "# Access training metrics for plotting\n",
        "print(f'Model with optimizer adamax - Final Training Accuracy: {history.history[\"accuracy\"][-1]}, Final Validation Accuracy: {history.history[\"val_accuracy\"][-1]}')\n"
      ],
      "metadata": {
        "id": "R8ITIoyF_fZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Evaluate the model with 'adamax' optimizer\n",
        "optimizer_name = 'adamax'\n",
        "model_path = f'/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_{optimizer_name}.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Evaluate the model on the \"test\" set\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "\n",
        "print(f'Model with optimizer {optimizer_name} - Test accuracy: {test_acc}, Test loss: {test_loss}')\n"
      ],
      "metadata": {
        "id": "0XdsbJbzBUgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
        "fig.suptitle('Training and Validation Metrics')\n",
        "\n",
        "# Evaluate the model with 'adamax' optimizer\n",
        "optimizer_name = 'adamax'\n",
        "model_path = f'/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_{optimizer_name}.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load training history\n",
        "history_path = f'/content/drive/MyDrive/VideoDataset/training_history_{optimizer_name}.pkl'  # Replace with the actual path\n",
        "with open(history_path, 'rb') as file:\n",
        "    history = pickle.load(file)\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(history['accuracy'], label=f'{optimizer_name} Training Accuracy')\n",
        "ax1.plot(history['val_accuracy'], label=f'{optimizer_name} Validation Accuracy')\n",
        "\n",
        "# Plot loss\n",
        "ax2.plot(history['loss'], label=f'{optimizer_name} Training Loss')\n",
        "ax2.plot(history['val_loss'], label=f'{optimizer_name} Validation Loss')\n",
        "\n",
        "# Set labels and title\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0v0Sq9Z8BavH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Function to preprocess an image for prediction\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n",
        "    return img_array, img\n",
        "\n",
        "# Choose a random image from the test folder\n",
        "test_images_folder = '/content/dataset/test'\n",
        "genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "random_genre = random.choice(genres)\n",
        "random_image_name = random.choice(os.listdir(os.path.join(test_images_folder, random_genre)))\n",
        "random_image_path = os.path.join(test_images_folder, random_genre, random_image_name)\n",
        "\n",
        "# Preprocess the image\n",
        "img, original_img = preprocess_image(random_image_path)\n",
        "\n",
        "# Load the 'adamax' model\n",
        "optimizer_name = 'adamax'\n",
        "model_path = f'/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_{optimizer_name}.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img)\n",
        "\n",
        "# Display the result along with the actual image and selected genre\n",
        "plt.imshow(original_img)\n",
        "plt.axis('off')\n",
        "\n",
        "print(f'Model with optimizer {optimizer_name}:')\n",
        "print(f'Selected from genre: {random_genre}')\n",
        "predicted_genre = genres[np.argmax(prediction)]\n",
        "plt.title(f'Predicted: {predicted_genre}')\n",
        "plt.show()\n",
        "print('---')\n"
      ],
      "metadata": {
        "id": "e2jrFELEBbq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "audioIndex = 0\n",
        "imageIndex = 0\n",
        "totalTime = 0\n",
        "\n",
        "# Load the 'adamax' model\n",
        "optimizer_name = 'adamax'\n",
        "model_path = '/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_adamax.h5'  # Replace with the actual path\n",
        "model = load_model(model_path)\n",
        "\n",
        "def preprocess_image(img):\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n",
        "    return img_array\n",
        "\n",
        "def predict_genre(img):\n",
        "    img_array = preprocess_image(img)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_genre = genres[np.argmax(prediction)]\n",
        "    return predicted_genre\n",
        "\n",
        "def extract_screenshots_and_audio(input_video_path, output_screenshots_folder, output_audio_folder):\n",
        "    global audioIndex, imageIndex, totalTime\n",
        "\n",
        "    # Create output folders if they don't exist\n",
        "    os.makedirs(output_screenshots_folder, exist_ok=True)\n",
        "    os.makedirs(output_audio_folder, exist_ok=True)\n",
        "\n",
        "    # Load video\n",
        "    video_clip = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Extract screenshots and calculate mean time duration\n",
        "    screenshots = []\n",
        "    mean_time_duration = 0\n",
        "    for timestamp in range(0, int(video_clip.duration), 5):\n",
        "        screenshot = video_clip.get_frame(timestamp)\n",
        "\n",
        "        # Convert NumPy array to PIL Image\n",
        "        pil_image = Image.fromarray(screenshot)\n",
        "\n",
        "        # Predict the genre using the 'adamax' model\n",
        "        predicted_genre = predict_genre(pil_image)\n",
        "\n",
        "        # Save screenshot with predicted genre as the filename\n",
        "        screenshot_path = os.path.join(output_screenshots_folder, f\"{predicted_genre}_{imageIndex}.png\")\n",
        "        imageIndex += 1\n",
        "        pil_image.save(screenshot_path)\n",
        "\n",
        "        screenshots.append(pil_image)\n",
        "        mean_time_duration += timestamp\n",
        "\n",
        "    totalTime += video_clip.duration\n",
        "\n",
        "    # Extract audio\n",
        "    audio = video_clip.audio\n",
        "    audio_path = os.path.join(output_audio_folder, f\"audio_{audioIndex}.wav\")\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "    audioIndex += 1  # Increment audio index for unique filenames\n",
        "\n",
        "    # Close video clip\n",
        "    video_clip.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_video_path = \"/content/drive/MyDrive/VideoDataset/TestVideos/videoplayback (1).mp4\"\n",
        "    output_screenshots_folder = \"/content/Test/screenshot\"\n",
        "    output_audio_folder = \"/content/Test/audio\"\n",
        "\n",
        "    genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "\n",
        "    # Call the function with the video file path\n",
        "    extract_screenshots_and_audio(input_video_path, output_screenshots_folder, output_audio_folder)\n",
        "\n",
        "    # Calculate average time (if needed)\n",
        "    averageTime = totalTime\n",
        "    print(averageTime)\n"
      ],
      "metadata": {
        "id": "YBTPiCLBB4Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "\n",
        "# Function to preprocess an image for prediction\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n",
        "    return img_array, img\n",
        "\n",
        "# Function to predict the genre using the 'adamax' model\n",
        "def predict_genre(img):\n",
        "    # Load the 'adamax' model\n",
        "    optimizer_name = 'adamax'\n",
        "    model_path = f'/content/drive/MyDrive/VideoDataset/video_analysis_vgg16_{optimizer_name}.h5'\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    if prediction[0][0] > 0.5:\n",
        "        return \"Mr.BeastType\"\n",
        "    else:\n",
        "        return \"MinimalistType\"\n",
        "\n",
        "# Initialize counters\n",
        "totalBeastVideos = 0\n",
        "totalMinVideos = 0\n",
        "\n",
        "# Loop through all screenshots\n",
        "for image_name in os.listdir(\"/content/Test/screenshot\"):\n",
        "    # Preprocess the image\n",
        "    image_path = os.path.join(\"/content/Test/screenshot\", image_name)\n",
        "    img, original_img = preprocess_image(image_path)\n",
        "\n",
        "    # Predict the genre using the 'adamax' model\n",
        "    predicted_genre = predict_genre(img)\n",
        "\n",
        "    # Update counters\n",
        "    if predicted_genre == 'Mr.BeastType':\n",
        "        totalBeastVideos += 1\n",
        "    else:\n",
        "        totalMinVideos += 1\n",
        "\n",
        "# Print the overall genre based on majority vote\n",
        "if totalBeastVideos > totalMinVideos:\n",
        "    print(\"Overall Genre: Mr.BeastType\")\n",
        "else:\n",
        "    print(\"Overall Genre: MinimalistType\")\n"
      ],
      "metadata": {
        "id": "f6K2Ql8ICoro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
        "\n",
        "# Function to extract MFCC features from audio files\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, mono=True, duration=5)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    return mfccs\n",
        "\n",
        "# List of genres\n",
        "genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "\n",
        "# List to store features and labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Load data for each genre\n",
        "for i, genre in enumerate(genres):\n",
        "    genre_path = f'/content/audio/{genre}'\n",
        "    for file_name in os.listdir(genre_path):\n",
        "        file_path = os.path.join(genre_path, file_name)\n",
        "        mfccs = extract_features(file_path)\n",
        "        features.append(mfccs)\n",
        "        labels.append(i)  # Assign a unique label for each genre\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Transpose the MFCCs before reshaping\n",
        "X_train = X_train.transpose(0, 2, 1)\n",
        "X_val = X_val.transpose(0, 2, 1)\n",
        "X_test = X_test.transpose(0, 2, 1)\n",
        "\n",
        "# Reshape the input data to match Conv1D input shape\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# Define and compile the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(genres), activation='softmax'))  # Output layer with softmax activation for multiple genres\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/VideoDataset/audio_analysis_multi_genre.h5')\n"
      ],
      "metadata": {
        "id": "M3fpwwxZDIow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "# Function to extract MFCC features from audio files\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, mono=True, duration=5)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    return mfccs\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/VideoDataset/audio_analysis_multi_genre.h5'  # Use the model trained for multiple genres\n",
        "model = load_model(model_path)\n",
        "\n",
        "# New audio file path\n",
        "new_audio_path = '/content/Test/audio/audio_0.wav'\n",
        "\n",
        "# Extract features from the new audio file\n",
        "new_audio_features = extract_features(new_audio_path)\n",
        "\n",
        "# Transpose and reshape the features\n",
        "new_audio_features = new_audio_features.transpose(1, 0)  # Transpose\n",
        "new_audio_features = new_audio_features.reshape(1, new_audio_features.shape[0], new_audio_features.shape[1])\n",
        "\n",
        "# Predict the class\n",
        "prediction = model.predict(new_audio_features)\n",
        "\n",
        "# Map the predicted class to a label\n",
        "genres = ['MrBeastType', 'VlogType', 'TechReviewType', 'GamingType', 'MinimalistType']\n",
        "predicted_class = genres[np.argmax(prediction)]\n",
        "\n",
        "# Print the prediction\n",
        "print(f\"Predicted Genre: {predicted_class}\")\n"
      ],
      "metadata": {
        "id": "Iwsl9ViQDK46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}