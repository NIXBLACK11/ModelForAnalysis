{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "AfKDdTrADm0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget 'https://storage.googleapis.com/kaggle-data-sets/568973/1032238/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240316%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240316T113744Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=6d6aee0b5f5088c0c27647b8fc54b38fd895e298fd25d2d1bec2fb4db65683c64dc9225450b6d1930f65c1284a35b7c530c8e8e24115ee4858a63daa466f47471091dddd421c7389b44c5429fc8d007031020f4c905f704c1570c3163ac67af2e10889c39677c30ee881b658383e72fa1469267df6a64fceda6bcb32cd86be2702556996948d444a9132a2eb1a620da07c8149782fc961a128e222d896b301500e3ed4226aa3dee096b14fadc4c4786cbe4006855c6fc1d12a83928f7431f101be67b99c8435f465568afcaaa741762c544e95954d0cba3e0f70cba4b05a2def8bd4ddd506b1ab3dc7cea739eaa84eda24739f53f5a0bc377fd774d1c7237fb8' -O archive.zip\n",
        "!git clone https://github.com/r0ckYr/AudioDataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1AY22pADps2",
        "outputId": "996e5f10-5803-4cf6-d11e-b64fdec59e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AudioDataset'...\n",
            "remote: Enumerating objects: 2437, done.\u001b[K\n",
            "remote: Total 2437 (delta 0), reused 0 (delta 0), pack-reused 2437\u001b[K\n",
            "Receiving objects: 100% (2437/2437), 363.94 MiB | 24.90 MiB/s, done.\n",
            "Updating files: 100% (2429/2429), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv AudioDataset data\n",
        "!rm -rf data/.git"
      ],
      "metadata": {
        "id": "zczFc6SPD7rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -type d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPIaoPetFLPJ",
        "outputId": "61d8edf4-1469-4d9d-e1cb-65af3de930c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "./.config\n",
            "./.config/configurations\n",
            "./.config/logs\n",
            "./.config/logs/2024.03.14\n",
            "./data\n",
            "./data/techreviewtype\n",
            "./data/mrbeasttype\n",
            "./data/testvideos\n",
            "./data/gamingtype\n",
            "./data/minimalisttype\n",
            "./data/vlogtype\n",
            "./sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/gamingtype/ | head -n1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls9Ik-tvD8Tn",
        "outputId": "c071ff9d-be23-47eb-d625-e8d08c7e94b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment_1000.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "aFuagUsUDjr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os"
      ],
      "metadata": {
        "id": "APVMqYhkG51m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_audio_features(file_path, mfcc=True, chroma=True, mel=True):\n",
        "    audio, sample_rate = librosa.load(file_path, mono=True, sr=None)\n",
        "\n",
        "    result = []\n",
        "\n",
        "    if mfcc or chroma or mel:\n",
        "        stft = np.abs(librosa.stft(audio))\n",
        "\n",
        "    if mfcc:\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        result.append(np.mean(mfccs.T, axis=0))\n",
        "\n",
        "    if chroma:\n",
        "        chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate)\n",
        "        result.append(np.mean(chroma.T, axis=0))\n",
        "\n",
        "    if mel:\n",
        "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
        "        result.append(np.mean(mel.T, axis=0))\n",
        "\n",
        "    return np.hstack(result)\n"
      ],
      "metadata": {
        "id": "8esiJHVNGsrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_audio_features2(file_path, mfcc=True, chroma=True, mel=True):\n",
        "    # Load audio file\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # Convert waveform to mono if it's stereo\n",
        "    if waveform.size(0) > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # Extract features\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = torchaudio.transforms.MFCC(sample_rate)(waveform)\n",
        "        mfccs = torch.mean(mfccs, dim=2).squeeze().numpy()  # Collapse the time dimension\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = librosa.feature.chroma_stft(y=waveform.numpy()[0], sr=sample_rate)\n",
        "        chroma = np.mean(chroma, axis=1)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = torchaudio.transforms.MelSpectrogram(sample_rate)(waveform)\n",
        "        mel = torch.mean(mel, dim=2).squeeze().numpy()  # Collapse the time dimension\n",
        "        result = np.hstack((result, mel))\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "FqAaomGtWLOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def compare_functions(file_path):\n",
        "    start_time = time.time()\n",
        "    output1 = extract_audio_features(file_path)\n",
        "    end_time = time.time()\n",
        "    time_taken1 = end_time - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    output2 = extract_audio_features2(file_path)\n",
        "    end_time = time.time()\n",
        "    time_taken2 = end_time - start_time\n",
        "\n",
        "    print(\"Time taken by extract_audio_features:\", time_taken1)\n",
        "    print(\"Time taken by extract_audio_features2:\", time_taken2)\n",
        "    print(\"Length of output1 :\", len(output1))\n",
        "    print(\"Length of output2 :\", len(output2))\n",
        "\n",
        "file_path = './data/gamingtype/segment_1000.mp3'\n",
        "compare_functions(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2EDickcYN6-",
        "outputId": "e7532abb-31e8-4119-b464-0adf00abc27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken by extract_audio_features: 0.1460733413696289\n",
            "Time taken by extract_audio_features2: 0.09493160247802734\n",
            "Length of output1 : 168\n",
            "Length of output2 : 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "data_dir = './data/'\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "\n",
        "def process_file(file_path):\n",
        "    return extract_audio_features2(file_path)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def process_class(label):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    file_paths = [os.path.join(class_dir, file_name) for file_name in os.listdir(class_dir)]\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        features = list(executor.map(process_file, file_paths))\n",
        "    X.extend(features)\n",
        "    Y.extend([classes.index(label)] * len(features))\n",
        "\n",
        "for label in classes:\n",
        "    process_class(label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN8IoSByFwwj",
        "outputId": "c30b410f-6de4-4c46-8839-d07198750a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=440\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './data/'\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "X = []\n",
        "Y = []\n",
        "for i, label in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        X.append(extract_audio_features2(file_path))\n",
        "        Y.append(i)"
      ],
      "metadata": {
        "id": "4EBbHW6MFRzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "Y = np.eye(len(classes))[Y]"
      ],
      "metadata": {
        "id": "xskk5U42b8et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "id": "5gN9EzydhzGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets (60% train, 20% validation)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting arrays\n",
        "print(\"Training set shapes:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"\\nValidation set shapes:\")\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"Y_val:\", Y_val.shape)\n",
        "print(\"\\nTesting set shapes:\")\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"Y_test:\", Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttDkyX-IzZxB",
        "outputId": "ad5c0006-c630-40fe-c82c-51015685cc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shapes:\n",
            "X_train: (1275, 180)\n",
            "Y_train: (1275, 6)\n",
            "\n",
            "Validation set shapes:\n",
            "X_val: (425, 180)\n",
            "Y_val: (425, 6)\n",
            "\n",
            "Testing set shapes:\n",
            "X_test: (729, 180)\n",
            "Y_test: (729, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input size : \",len(X[0]))\n",
        "print(\"Training Size :\", len(X))\n",
        "print(\"Lables Size :\", len(Y[0]))\n",
        "print(\"Lables : \",Y[0])\n",
        "# print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70VitSgGYM9-",
        "outputId": "e79f3138-993b-4085-985d-556fb86a1bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size :  180\n",
            "Training Size : 2429\n",
            "Lables Size : 6\n",
            "Lables :  [1. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "      self.X = torch.tensor(X, dtype=torch.float32)\n",
        "      self.Y = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "train_dataset = AudioDataset(X_train, Y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = AudioDataset(X_test, Y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "validation_dataset = AudioDataset(X_val, Y_val)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "or_DE6ItILD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "35f27opKMvGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioModel(nn.Module):\n",
        "    def __init__(self, input_channels, output_size):\n",
        "        super(AudioModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(64 * 45, 128)  # Adjusted output size based on input dimensions\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 64 * 45)  # Flatten before passing to fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "v-b5_K2kMLXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "UjRPApKjNBeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(X[0])\n",
        "output_size = len(classes)\n",
        "in_channels = 1\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "P9S0rSqNW_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AudioModel(in_channels, output_size).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "pJKd6zLVM1d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, batch_outputs in dataloader:\n",
        "            batch_inputs = batch_inputs.view(batch_inputs.size(0), 1, -1)  # Reshape input\n",
        "            batch_outputs = batch_outputs.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_inputs)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted_labels = torch.max(outputs, 1)\n",
        "\n",
        "            # Count correct predictions\n",
        "            correct_predictions += (predicted_labels == batch_outputs.argmax(dim=-1)).sum().item()\n",
        "            total_samples += batch_inputs.size(0)\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    model.train()  # Set the model back to training mode\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "D61WU-4cbS44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs+1):\n",
        "    for batch_inputs, batch_outputs in train_loader:\n",
        "        batch_inputs = batch_inputs.view(batch_inputs.size(0), 1, -1)\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_outputs = batch_outputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    if epoch % (num_epochs//10) == 0:\n",
        "        train_accuracy = calculate_accuracy(model, validation_loader, device)\n",
        "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss.item()}, Training Accuracy: {train_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTk5Y_S8U-34",
        "outputId": "14ecd41e-f306-4e66-97cf-7211ec6c02b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100, Loss: 0.0806858018040657, Training Accuracy: 57.88%\n",
            "Epoch 10/100, Loss: 0.029215466231107712, Training Accuracy: 84.47%\n",
            "Epoch 20/100, Loss: 0.030978325754404068, Training Accuracy: 91.53%\n",
            "Epoch 30/100, Loss: 0.006983374245464802, Training Accuracy: 92.47%\n",
            "Epoch 40/100, Loss: 0.006424411665648222, Training Accuracy: 95.06%\n",
            "Epoch 50/100, Loss: 0.022984866052865982, Training Accuracy: 95.29%\n",
            "Epoch 60/100, Loss: 0.02022213488817215, Training Accuracy: 95.53%\n",
            "Epoch 70/100, Loss: 0.01149623841047287, Training Accuracy: 96.24%\n",
            "Epoch 80/100, Loss: 0.012001162394881248, Training Accuracy: 96.00%\n",
            "Epoch 90/100, Loss: 0.0026459433138370514, Training Accuracy: 96.47%\n",
            "Epoch 100/100, Loss: 0.00032249881769530475, Training Accuracy: 96.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = calculate_accuracy(model, test_loader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "RGWFzRv_0aYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59c3e06-2815-47d2-81ee-3f489f1f9f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "nOcsTYhfIVr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!mkdir output"
      ],
      "metadata": {
        "id": "baaxl3MtLJo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import logging\n",
        "logging.getLogger(\"moviepy\").setLevel(logging.ERROR)\n",
        "\n",
        "def video_to_audio(video_file, audio_file):\n",
        "    video = VideoFileClip(video_file)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(audio_file)\n",
        "\n",
        "def segment_audio(audio_file, output_dir, segment_duration=10):\n",
        "    audio = AudioFileClip(audio_file)\n",
        "    duration = audio.duration\n",
        "    segments = int(duration // segment_duration)\n",
        "\n",
        "    for i in range(segments):\n",
        "        start_time = i * segment_duration\n",
        "        end_time = min((i + 1) * segment_duration, duration)\n",
        "        segment = audio.subclip(start_time, end_time)\n",
        "        segment_file = os.path.join(output_dir, f\"segment_{i+1}.mp3\")\n",
        "        segment.write_audiofile(segment_file)\n",
        "\n",
        "    # Handle the last segment\n",
        "    if duration % segment_duration != 0:\n",
        "        start_time = segments * segment_duration\n",
        "        segment = audio.subclip(start_time, duration)\n",
        "        segment_file = os.path.join(output_dir, f\"segment_{segments+1}.mp3\")\n",
        "        segment.write_audiofile(segment_file)\n",
        "\n",
        "\n",
        "# Input video file\n",
        "video_file = \"videoplayback.mp4\"\n",
        "output_dir = \"output\"\n",
        "\n",
        "# Convert video to audio\n",
        "audio_file = os.path.join(output_dir, \"audio.mp3\")\n",
        "video_to_audio(video_file, audio_file)\n",
        "\n",
        "# Segment and classify audio\n",
        "segment_audio(audio_file, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_2jayuKJqtl",
        "outputId": "94f43edf-bc1f-430b-8362-babd1d3777d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in output/audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_1.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_2.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_3.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_4.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_5.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_6.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_7.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_8.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_9.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_10.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_11.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_12.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_13.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_14.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_15.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_16.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_17.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_18.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_19.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_20.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_21.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_22.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_23.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_24.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_25.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_26.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_27.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_28.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_29.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_30.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_31.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_32.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_33.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_34.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_35.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_36.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_37.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_38.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_39.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_40.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_41.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_42.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in output/segment_43.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "model_path = \"model.pth\"\n",
        "model = AudioModel(in_channels, output_size).to(device)  # Make sure to create an instance of your model before loading the state_dict\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo-tNxgkMGgb",
        "outputId": "2dc14a81-52b0-4b95-e9c9-287e11512ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AudioModel(\n",
              "  (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=2880, out_features=128, bias=True)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_segment(segment_file):\n",
        "    features = extract_audio_features2(segment_file)\n",
        "    features = torch.tensor(features, dtype=torch.float32).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(features)\n",
        "\n",
        "    probabilities = torch.softmax(outputs, dim=1).squeeze().numpy()\n",
        "\n",
        "    class_probabilities = {classes[i]: probabilities[i] for i in range(len(classes))}\n",
        "\n",
        "    return class_probabilities\n",
        "\n",
        "\n",
        "def classify_all_segments(segment_files):\n",
        "    class_probabilities_sum = {label: 0.0 for label in classes}\n",
        "    total_segments = len(segment_files)\n",
        "\n",
        "    for segment_file in segment_files:\n",
        "        class_probabilities = classify_segment(segment_file)\n",
        "        for label, probability in class_probabilities.items():\n",
        "            class_probabilities_sum[label] += probability\n",
        "\n",
        "\n",
        "    average_probabilities = {label: class_probabilities_sum[label] / total_segments for label in classes}\n",
        "    return average_probabilities\n",
        "\n",
        "import os\n",
        "\n",
        "def get_segment_files(directory):\n",
        "    segment_files = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.startswith(\"segment_\") and file.endswith(\".mp3\"):\n",
        "                segment_files.append(os.path.join(root, file))\n",
        "    return segment_files\n",
        "\n",
        "output_directory = \"output\"\n",
        "segment_files = get_segment_files(output_directory)\n",
        "\n",
        "\n",
        "average_predictions = classify_all_segments(segment_files)\n",
        "print(\"Average predictions:\", average_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzqLIMy8JnER",
        "outputId": "a1a0a3af-79f7-404e-cb62-653e2a304acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average predictions: {'gamingtype': 0.13111372049464737, 'minimalisttype': 0.17070840472398802, 'mrbeasttype': 0.3017819915399995, 'techreviewtype': 0.13145868341590083, 'testvideos': 0.1326339282961779, 'vlogtype': 0.13230327014313187}\n"
          ]
        }
      ]
    }
  ]
}